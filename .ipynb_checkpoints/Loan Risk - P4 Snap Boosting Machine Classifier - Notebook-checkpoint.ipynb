{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/notebooks/headers/AutoAI-Banner_Pipeline-Notebook.svg)\n",
    "# Pipeline 4 Notebook - AutoAI Notebook v1.22.9\n",
    "\n",
    "Consider these tips for working with an auto-generated notebook:\n",
    "- Notebook code generated using AutoAI will execute successfully. If you modify the notebook, we cannot guarantee it will run successfully.\n",
    "- This pipeline is optimized for the original data set. The pipeline might fail or produce sub-optimal results if used with different data.  If you want to use a different data set, consider retraining the AutoAI experiment to generate a new pipeline. For more information, see <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Cloud Platform</a>. \n",
    "- Before modifying the pipeline or trying to re-fit the pipeline, consider that the code converts dataframes to numpy arrays before fitting the pipeline (a current restriction of the preprocessor pipeline).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"content\"></a>\n",
    "## Notebook content\n",
    "\n",
    "This notebook contains a Scikit-learn representation of AutoAI pipeline. This notebook introduces commands for retrieving data, training the model, and testing the model. \n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.10 and scikit-learn 1.1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Notebook goals\n",
    "\n",
    "-  Scikit-learn pipeline definition\n",
    "-  Pipeline training \n",
    "-  Pipeline evaluation\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "**[Setup](#setup)**<br>\n",
    "&nbsp;&nbsp;[Package installation](#install)<br>\n",
    "&nbsp;&nbsp;[AutoAI experiment metadata](#variables_definition)<br>\n",
    "&nbsp;&nbsp;[Watson Machine Learning connection](#connection)<br>\n",
    "**[Pipeline inspection](#inspection)** <br>\n",
    "&nbsp;&nbsp;[Read training data](#read)<br>\n",
    "&nbsp;&nbsp;[Train and test data split](#split)<br>\n",
    "&nbsp;&nbsp;[Create pipeline](#preview_model_to_python_code)<br>\n",
    "&nbsp;&nbsp;[Train pipeline model](#train)<br>\n",
    "&nbsp;&nbsp;[Test pipeline model](#test_model)<br>\n",
    "**[Store the model](#saving)**<br>\n",
    "**[Summary and next steps](#summary_and_next_steps)**<br>\n",
    "**[Copyrights](#copyrights)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install\"></a>\n",
    "## Package installation\n",
    "Before you use the sample code in this notebook, install the following packages:\n",
    " - ibm-watsonx-ai,\n",
    " - autoai-libs,\n",
    " - scikit-learn,\n",
    " - snapml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:00:45.009458Z",
     "iopub.status.busy": "2020-10-12T14:00:45.007968Z",
     "iopub.status.idle": "2020-10-12T14:00:46.037702Z",
     "shell.execute_reply": "2020-10-12T14:00:46.038270Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.10.0 in ./.conda/lib/python3.12/site-packages (from lomond->ibm-watsonx-ai) (1.16.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement autoai-libs (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for autoai-libs\u001b[0m\u001b[31m\n",
      "\u001b[0m  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[33 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/Lebang/Desktop/code/IBM-ML-practice/.conda/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/Lebang/Desktop/code/IBM-ML-practice/.conda/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/Lebang/Desktop/code/IBM-ML-practice/.conda/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 112, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     backend = _build_backend()\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/Lebang/Desktop/code/IBM-ML-practice/.conda/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 77, in _build_backend\n",
      "  \u001b[31m   \u001b[0m     obj = import_module(mod_path)\n",
      "  \u001b[31m   \u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/Lebang/Desktop/code/IBM-ML-practice/.conda/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "  \u001b[31m   \u001b[0m     return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/tn/04rchm0j3536t6jqstjnpt2h0000gq/T/pip-build-env-os6p83wy/overlay/lib/python3.12/site-packages/setuptools/__init__.py\", line 16, in <module>\n",
      "  \u001b[31m   \u001b[0m     import setuptools.version\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/tn/04rchm0j3536t6jqstjnpt2h0000gq/T/pip-build-env-os6p83wy/overlay/lib/python3.12/site-packages/setuptools/version.py\", line 1, in <module>\n",
      "  \u001b[31m   \u001b[0m     import pkg_resources\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/tn/04rchm0j3536t6jqstjnpt2h0000gq/T/pip-build-env-os6p83wy/overlay/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 2172, in <module>\n",
      "  \u001b[31m   \u001b[0m     register_finder(pkgutil.ImpImporter, find_on_path)\n",
      "  \u001b[31m   \u001b[0m                     ^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[33 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/Lebang/Desktop/code/IBM-ML-practice/.conda/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/Lebang/Desktop/code/IBM-ML-practice/.conda/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/Lebang/Desktop/code/IBM-ML-practice/.conda/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 112, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     backend = _build_backend()\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/Lebang/Desktop/code/IBM-ML-practice/.conda/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 77, in _build_backend\n",
      "  \u001b[31m   \u001b[0m     obj = import_module(mod_path)\n",
      "  \u001b[31m   \u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/Lebang/Desktop/code/IBM-ML-practice/.conda/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "  \u001b[31m   \u001b[0m     return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/tn/04rchm0j3536t6jqstjnpt2h0000gq/T/pip-build-env-gzw24e59/overlay/lib/python3.12/site-packages/setuptools/__init__.py\", line 16, in <module>\n",
      "  \u001b[31m   \u001b[0m     import setuptools.version\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/tn/04rchm0j3536t6jqstjnpt2h0000gq/T/pip-build-env-gzw24e59/overlay/lib/python3.12/site-packages/setuptools/version.py\", line 1, in <module>\n",
      "  \u001b[31m   \u001b[0m     import pkg_resources\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/tn/04rchm0j3536t6jqstjnpt2h0000gq/T/pip-build-env-gzw24e59/overlay/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 2172, in <module>\n",
      "  \u001b[31m   \u001b[0m     register_finder(pkgutil.ImpImporter, find_on_path)\n",
      "  \u001b[31m   \u001b[0m                     ^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement snapml==1.13.2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for snapml==1.13.2\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ibm-watsonx-ai | tail -n 1\n",
    "!pip install autoai-libs==1.17.2 | tail -n 1\n",
    "!pip install scikit-learn==1.1.1 | tail -n 1\n",
    "!pip install -U 'lale>=0.7,<0.8' | tail -n 1\n",
    "!pip install snapml==1.13.2 | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter warnings for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"variables_definition\"></a>\n",
    "## AutoAI experiment metadata\n",
    "The following cell contains the training data connection details.  \n",
    "**Note**: The connection might contain authorization credentials, so be careful when sharing the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:00:49.797633Z",
     "iopub.status.busy": "2020-10-12T14:00:49.796778Z",
     "iopub.status.idle": "2020-10-12T14:00:57.182715Z",
     "shell.execute_reply": "2020-10-12T14:00:57.183132Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.helpers import DataConnection\n",
    "from ibm_watsonx_ai.helpers import ContainerLocation\n",
    "\n",
    "training_data_references = [\n",
    "    DataConnection(\n",
    "        data_asset_id='0ccfe638-37ae-46c2-9efb-2e2ff4c9cf6d'\n",
    "    ),\n",
    "]\n",
    "training_result_reference = DataConnection(\n",
    "    location=ContainerLocation(\n",
    "        path='auto_ml/3832768b-12f2-4074-8827-b4d690d75d88/wml_data/ffc59a66-79f4-492c-83f0-3b5e376a7e84/data/automl',\n",
    "        model_location='auto_ml/3832768b-12f2-4074-8827-b4d690d75d88/wml_data/ffc59a66-79f4-492c-83f0-3b5e376a7e84/data/automl/model.zip',\n",
    "        training_status='auto_ml/3832768b-12f2-4074-8827-b4d690d75d88/wml_data/ffc59a66-79f4-492c-83f0-3b5e376a7e84/training-status.json'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains input parameters provided to run the AutoAI experiment in Watson Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:00:57.187305Z",
     "iopub.status.busy": "2020-10-12T14:00:57.186602Z",
     "iopub.status.idle": "2020-10-12T14:00:57.188392Z",
     "shell.execute_reply": "2020-10-12T14:00:57.188878Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiment_metadata = dict(\n",
    "    prediction_type='binary',\n",
    "    prediction_column='Risk',\n",
    "    holdout_size=0.1,\n",
    "    scoring='accuracy',\n",
    "    csv_separator=',',\n",
    "    random_state=33,\n",
    "    max_number_of_estimators=2,\n",
    "    training_data_references=training_data_references,\n",
    "    training_result_reference=training_result_reference,\n",
    "    include_only_estimators=['RandomForestClassifierEstimator', 'DecisionTreeClassifierEstimator', 'LogisticRegressionEstimator', 'ExtraTreesClassifierEstimator', 'XGBClassifierEstimator', 'LGBMClassifierEstimator', 'SnapDecisionTreeClassifierEstimator', 'SnapRandomForestClassifierEstimator', 'SnapBoostingMachineClassifierEstimator', 'SnapLogisticRegressionEstimator', 'SnapSVMClassifierEstimator', 'GradientBoostingClassifierEstimator'],\n",
    "    deployment_url='https://eu-de.ml.cloud.ibm.com',\n",
    "    project_id='de1a04a8-8039-4504-91d9-db3db073a121',\n",
    "    train_sample_columns_index_list=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19],\n",
    "    positive_label='No Risk',\n",
    "    drop_duplicates=True,\n",
    "    include_batched_ensemble_estimators=[],\n",
    "    feature_selector_mode='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"connection\"></a>\n",
    "## Watson Machine Learning connection\n",
    "\n",
    "This cell defines the credentials required to work with the Watson Machine Learning service.\n",
    "\n",
    "**Action**: Provide the IBM Cloud apikey, For details, see [documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'PUT_YOUR_APIKEY_HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\": api_key,\n",
    "    \"url\": experiment_metadata['deployment_url']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting IAM Token.\n",
      "Reason: <Response [400]>\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Error getting IAM Token.\nReason: <Response [400]>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mibm_watsonx_ai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m APIClient\n\u001b[0;32m----> 3\u001b[0m wml_client \u001b[38;5;241m=\u001b[39m APIClient(wml_credentials)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspace_id\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m experiment_metadata:\n\u001b[1;32m      6\u001b[0m     wml_client\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39mdefault_space(experiment_metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspace_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ibm_watsonx_ai/client.py:365\u001b[0m, in \u001b[0;36mAPIClient.__init__\u001b[0;34m(self, credentials, project_id, space_id, verify, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# For cloud, service_instance.details will be set during space creation( if instance is associated ) or\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# while patching a space with an instance\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice_instance: ServiceInstance \u001b[38;5;241m=\u001b[39m ServiceInstance(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolumes \u001b[38;5;241m=\u001b[39m Volume(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_fm_ga_api:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ibm_watsonx_ai/service_instance.py:56\u001b[0m, in \u001b[0;36mServiceInstance.__init__\u001b[0;34m(self, client)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# This is used in connections.py\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_href_definitions \u001b[38;5;241m=\u001b[39m HrefDefinitions(\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mCLOUD_PLATFORM_SPACES,\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mPLATFORM_URL,\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES,\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_token()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mproceed:  \u001b[38;5;66;03m# there is no 'token' in credentials\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_expiration_datetime() \u001b[38;5;241m-\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ibm_watsonx_ai/service_instance.py:237\u001b[0m, in \u001b[0;36mServiceInstance._get_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_token\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_token()\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_token_refresh_possible():\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ibm_watsonx_ai/service_instance.py:273\u001b[0m, in \u001b[0;36mServiceInstance._create_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mCLOUD_PLATFORM_SPACES:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_is_IAM():\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_IAM_token()\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\n\u001b[1;32m    276\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key for IAM token is not provided in credentials for the client.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ibm_watsonx_ai/service_instance.py:345\u001b[0m, in \u001b[0;36mServiceInstance._get_IAM_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expiration_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError getting IAM Token.\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m token\n",
      "\u001b[0;31mWMLClientError\u001b[0m: Error getting IAM Token.\nReason: <Response [400]>"
     ]
    }
   ],
   "source": [
    "from ibm_watsonx_ai import APIClient\n",
    "\n",
    "wml_client = APIClient(wml_credentials)\n",
    "\n",
    "if 'space_id' in experiment_metadata:\n",
    "    wml_client.set.default_space(experiment_metadata['space_id'])\n",
    "else:\n",
    "    wml_client.set.default_project(experiment_metadata['project_id'])\n",
    "    \n",
    "training_data_references[0].set_client(wml_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"inspection\"></a>\n",
    "# Pipeline inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"read\"></a>\n",
    "## Read training data\n",
    "\n",
    "Retrieve training dataset from AutoAI experiment as pandas DataFrame.\n",
    "\n",
    "**Note**: If reading data results in an error, provide data as Pandas DataFrame object, for example, reading .CSV file with `pandas.read_csv()`. \n",
    "\n",
    "It may be necessary to use methods for initial data pre-processing like: e.g. `DataFrame.dropna()`, `DataFrame.drop_duplicates()`, `DataFrame.sample()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:01:16.076169Z",
     "iopub.status.busy": "2020-10-12T14:01:16.075589Z",
     "iopub.status.idle": "2020-10-12T14:01:19.190233Z",
     "shell.execute_reply": "2020-10-12T14:01:19.190807Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = training_data_references[0].read(experiment_metadata=experiment_metadata, with_holdout_split=True, use_flight=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"preview_model_to_python_code\"></a>\n",
    "## Create pipeline\n",
    "In the next cell, you can find the Scikit-learn definition of the selected AutoAI pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from autoai_libs.transformers.exportable import ColumnSelector\n",
    "from autoai_libs.transformers.exportable import NumpyColumnSelector\n",
    "from autoai_libs.transformers.exportable import CompressStrings\n",
    "from autoai_libs.transformers.exportable import NumpyReplaceMissingValues\n",
    "from autoai_libs.transformers.exportable import NumpyReplaceUnknownValues\n",
    "from autoai_libs.transformers.exportable import boolean2float\n",
    "from autoai_libs.transformers.exportable import CatImputer\n",
    "from autoai_libs.transformers.exportable import CatEncoder\n",
    "import numpy as np\n",
    "from autoai_libs.transformers.exportable import float32_transform\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from autoai_libs.transformers.exportable import FloatStr2Float\n",
    "from autoai_libs.transformers.exportable import NumImputer\n",
    "from autoai_libs.transformers.exportable import OptStandardScaler\n",
    "from sklearn.pipeline import make_union\n",
    "from autoai_libs.transformers.exportable import NumpyPermuteArray\n",
    "from autoai_libs.cognito.transforms.transform_utils import TAM\n",
    "from sklearn.decomposition import PCA\n",
    "from autoai_libs.cognito.transforms.transform_utils import FS1\n",
    "from autoai_libs.cognito.transforms.transform_utils import TA1\n",
    "import autoai_libs.utils.fc_methods\n",
    "from snapml import SnapBoostingMachineClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing & Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "column_selector_0 = ColumnSelector(\n",
    "    columns_indices_list=[\n",
    "        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19,\n",
    "    ]\n",
    ")\n",
    "numpy_column_selector_0 = NumpyColumnSelector(\n",
    "    columns=[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    ")\n",
    "compress_strings = CompressStrings(\n",
    "    compress_type=\"hash\",\n",
    "    dtypes_list=[\n",
    "        \"char_str\", \"float_int_num\", \"char_str\", \"char_str\", \"char_str\",\n",
    "        \"char_str\", \"float_int_num\", \"char_str\", \"char_str\", \"float_int_num\",\n",
    "        \"char_str\", \"float_int_num\", \"char_str\", \"char_str\", \"float_int_num\",\n",
    "        \"char_str\", \"float_int_num\", \"char_str\",\n",
    "    ],\n",
    "    missing_values_reference_list=[\"\", \"-\", \"?\", float(\"nan\")],\n",
    "    misslist_list=[\n",
    "        [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [],\n",
    "        [],\n",
    "    ],\n",
    ")\n",
    "numpy_replace_missing_values_0 = NumpyReplaceMissingValues(\n",
    "    filling_values=float(\"nan\"), missing_values=[]\n",
    ")\n",
    "numpy_replace_unknown_values = NumpyReplaceUnknownValues(\n",
    "    filling_values=float(\"nan\"),\n",
    "    filling_values_list=[\n",
    "        float(\"nan\"), 100001, float(\"nan\"), float(\"nan\"), float(\"nan\"),\n",
    "        float(\"nan\"), 100001, float(\"nan\"), float(\"nan\"), 100001,\n",
    "        float(\"nan\"), 100001, float(\"nan\"), float(\"nan\"), 100001,\n",
    "        float(\"nan\"), 100001, float(\"nan\"),\n",
    "    ],\n",
    "    missing_values_reference_list=[\"\", \"-\", \"?\", float(\"nan\")],\n",
    ")\n",
    "cat_imputer = CatImputer(\n",
    "    missing_values=float(\"nan\"),\n",
    "    sklearn_version_family=\"1\",\n",
    "    strategy=\"most_frequent\",\n",
    ")\n",
    "cat_encoder = CatEncoder(\n",
    "    dtype=np.float64,\n",
    "    handle_unknown=\"error\",\n",
    "    sklearn_version_family=\"1\",\n",
    "    encoding=\"ordinal\",\n",
    "    categories=\"auto\",\n",
    ")\n",
    "pipeline_0 = make_pipeline(\n",
    "    column_selector_0,\n",
    "    numpy_column_selector_0,\n",
    "    compress_strings,\n",
    "    numpy_replace_missing_values_0,\n",
    "    numpy_replace_unknown_values,\n",
    "    boolean2float(),\n",
    "    cat_imputer,\n",
    "    cat_encoder,\n",
    "    float32_transform(),\n",
    ")\n",
    "column_selector_1 = ColumnSelector(\n",
    "    columns_indices_list=[\n",
    "        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19,\n",
    "    ]\n",
    ")\n",
    "numpy_column_selector_1 = NumpyColumnSelector(columns=[4])\n",
    "float_str2_float = FloatStr2Float(\n",
    "    dtypes_list=[\"float_int_num\"], missing_values_reference_list=[]\n",
    ")\n",
    "numpy_replace_missing_values_1 = NumpyReplaceMissingValues(\n",
    "    filling_values=float(\"nan\"), missing_values=[]\n",
    ")\n",
    "num_imputer = NumImputer(missing_values=float(\"nan\"), strategy=\"median\")\n",
    "opt_standard_scaler = OptStandardScaler(use_scaler_flag=False)\n",
    "pipeline_1 = make_pipeline(\n",
    "    column_selector_1,\n",
    "    numpy_column_selector_1,\n",
    "    float_str2_float,\n",
    "    numpy_replace_missing_values_1,\n",
    "    num_imputer,\n",
    "    opt_standard_scaler,\n",
    "    float32_transform(),\n",
    ")\n",
    "union = make_union(pipeline_0, pipeline_1)\n",
    "numpy_permute_array = NumpyPermuteArray(\n",
    "    axis=0,\n",
    "    permutation_indices=[\n",
    "        0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 4,\n",
    "    ],\n",
    ")\n",
    "tam = TAM(\n",
    "    tans_class=PCA(),\n",
    "    name=\"pca\",\n",
    "    col_names=[\n",
    "        \"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\",\n",
    "        \"LoanAmount\", \"ExistingSavings\", \"EmploymentDuration\",\n",
    "        \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\",\n",
    "        \"CurrentResidenceDuration\", \"OwnsProperty\", \"Age\", \"InstallmentPlans\",\n",
    "        \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n",
    "        \"ForeignWorker\",\n",
    "    ],\n",
    "    col_dtypes=[\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"),\n",
    "    ],\n",
    ")\n",
    "fs1_0 = FS1(\n",
    "    cols_ids_must_keep=range(0, 19),\n",
    "    additional_col_count_to_keep=15,\n",
    "    ptype=\"classification\",\n",
    ")\n",
    "ta1 = TA1(\n",
    "    fun=np.square,\n",
    "    name=\"square\",\n",
    "    datatypes=[\"numeric\"],\n",
    "    feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical],\n",
    "    col_names=[\n",
    "        \"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\",\n",
    "        \"LoanAmount\", \"ExistingSavings\", \"EmploymentDuration\",\n",
    "        \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\",\n",
    "        \"CurrentResidenceDuration\", \"OwnsProperty\", \"Age\", \"InstallmentPlans\",\n",
    "        \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n",
    "        \"ForeignWorker\", \"pca_0\", \"pca_1\", \"pca_2\", \"pca_4\", \"pca_5\", \"pca_6\",\n",
    "        \"pca_8\", \"pca_9\", \"pca_10\", \"pca_12\", \"pca_13\", \"pca_14\", \"pca_15\",\n",
    "        \"pca_16\", \"pca_18\",\n",
    "    ],\n",
    "    col_dtypes=[\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n",
    "        np.dtype(\"float32\"),\n",
    "    ],\n",
    ")\n",
    "fs1_1 = FS1(\n",
    "    cols_ids_must_keep=range(0, 19),\n",
    "    additional_col_count_to_keep=15,\n",
    "    ptype=\"classification\",\n",
    ")\n",
    "snap_boosting_machine_classifier = SnapBoostingMachineClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    gpu_ids=[0],\n",
    "    learning_rate=0.29647372337700506,\n",
    "    min_max_depth=3,\n",
    "    num_round=82,\n",
    "    random_state=33,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    union,\n",
    "    numpy_permute_array,\n",
    "    tam,\n",
    "    fs1_0,\n",
    "    ta1,\n",
    "    fs1_1,\n",
    "    snap_boosting_machine_classifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## Train pipeline model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define scorer from the optimization metric\n",
    "This cell constructs the cell scorer based on the experiment metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "scorer = get_scorer(experiment_metadata['scoring'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"test_model\"></a>\n",
    "### Fit pipeline model\n",
    "In this cell, the pipeline is fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:01:19.291734Z",
     "iopub.status.busy": "2020-10-12T14:01:19.244735Z",
     "iopub.status.idle": "2020-10-12T14:01:19.338461Z",
     "shell.execute_reply": "2020-10-12T14:01:19.338958Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X_train.values, y_train.values.ravel());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test_model\"></a>\n",
    "## Test pipeline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Score the fitted pipeline with the generated scorer using the holdout dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-12T14:02:03.910267Z",
     "iopub.status.busy": "2020-10-12T14:02:03.909710Z",
     "iopub.status.idle": "2020-10-12T14:02:03.914154Z",
     "shell.execute_reply": "2020-10-12T14:02:03.914727Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = scorer(pipeline, X_test.values, y_test.values)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.predict(X_test.values[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"saving\"></a>\n",
    "## Store the model\n",
    "\n",
    "In this section you will learn how to store the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = {\n",
    "    wml_client.repository.ModelMetaNames.NAME: 'P4 - Pretrained AutoAI pipeline'\n",
    "}\n",
    "\n",
    "stored_model_details = wml_client.repository.store_model(model=pipeline, meta_props=model_metadata, experiment_metadata=experiment_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the stored model details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_model_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<a id=\"deployment\"></a>\n",
    "## Create online deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "You can use commands bellow to promote the model to space and create online deployment (web service).\n",
    "\n",
    "<a id=\"working_spaces\"></a>\n",
    "### Working with spaces\n",
    "\n",
    "In this section you will specify a deployment space for organizing the assets for deploying and scoring the model. If you do not have an existing space, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas) to create a new space, following these steps:\n",
    "\n",
    "- Click **New Deployment Space**.\n",
    "- Create an empty space.\n",
    "- Select Cloud Object Storage.\n",
    "- Select Watson Machine Learning instance and press **Create**.\n",
    "- Copy `space_id` and paste it below.\n",
    "\n",
    "**Tip**: You can also use the API to prepare the space for your work. Learn more [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
    "\n",
    "**Action**: Assign or update space ID below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "space_id = \"PUT_YOUR_SPACE_ID_HERE\"\n",
    "\n",
    "model_id = wml_client.spaces.promote(asset_id=stored_model_details[\"metadata\"][\"id\"], source_project_id=experiment_metadata[\"project_id\"], target_space_id=space_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Prepare online deployment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "wml_client.set.default_space(space_id)\n",
    "\n",
    "deploy_meta = {\n",
    "        wml_client.deployments.ConfigurationMetaNames.NAME: \"Incrementally trained AutoAI pipeline\",\n",
    "        wml_client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
    "    }\n",
    "\n",
    "deployment_details = wml_client.deployments.create(artifact_uid=model_id, meta_props=deploy_meta)\n",
    "deployment_id = wml_client.deployments.get_id(deployment_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Test online deployment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "scoring_payload = {\n",
    "    \"input_data\": [{\n",
    "        'values': pd.DataFrame(X_test[:5])\n",
    "    }]\n",
    "}\n",
    "\n",
    "wml_client.deployments.score(deployment_id, scoring_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "### Deleting deployment\n",
    "You can delete the existing deployment by calling the `wml_client.deployments.delete(deployment_id)` command.\n",
    "To list the existing web services, use `wml_client.deployments.list()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary_and_next_steps\"></a>\n",
    "# Summary and next steps\n",
    "You successfully completed this notebook!\n",
    "You learned how to use AutoAI pipeline definition to train the model.\n",
    "Check out our [Online Documentation](https://www.ibm.com/cloud/watson-studio/autoai) for more samples, tutorials, documentation, how-tos, and blog posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"copyrights\"></a>\n",
    "### Copyrights\n",
    "\n",
    "Licensed Materials - Copyright © 2024 IBM. This notebook and its source code are released under the terms of the ILAN License. Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
    "\n",
    "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
    "\n",
    "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\">License Terms</a>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
